{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Beginner's Guide to Google's Vision API in Python</center>\n",
    "\n",
    "**Learn what is Vision API and what are all the things that it offers. By the end of this tutorial, you will also learn how you can call Vision API from your Python code.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's been quite a while Google released a dedicated API called **[Vision API](https://cloud.google.com/vision/)** for performing _computer vision_ related tasks. Computer vision is a field that concerns how a computer processes an image. It is quite easy for us humans to derive any useful insights from a given image but how a computer does it? \n",
    "\n",
    "Say, for example, you supply an image of a dog to your computer and using some software the computer tells you that the image supplied to it is a dog's image. This is where computer vision comes in. Computer vision is a whole world of study onto itself and the _Vision API_ provides a number of utilities for performing tasks related to computer vision with absolute ease. The best part is that developers with absolutely no previous experience in computer vision can use _Vision API_ by going through its [documentation](https://cloud.google.com/vision/overview/docs/). \n",
    "\n",
    "This tutorial attempts to introduce you with the _Vision API_ and how it can be called from Python code. Specifically speaking, this tutorial is going to cover:\n",
    "- What is Google's Vision API (a more detailed introduction)\n",
    "- What are the offerings of Vision API\n",
    "- Vision API Client Library for Python\n",
    "- A case study with Vision API in Python\n",
    "\n",
    "**Note**: If you feel that you want to know more about APIs in general (from Python and Machine Learning perspectives) before getting started with this tutorial following are some good resources: \n",
    "- [An Introduction to APIs](https://www.analyticsvidhya.com/blog/2016/11/an-introduction-to-apis-application-programming-interfaces-5-apis-a-data-scientist-must-know/)\n",
    "- [Turning Machine Learning Models into APIs in Python](https://www.datacamp.com/community/tutorials/machine-learning-models-api-python?tap_a=5644-dce66f&tap_s=3575)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Google's Vision API (a more detailed introduction)?\n",
    "\n",
    "Google have encapsulated their Machine Learning models in an API to allow developers to use their Vision technology. The Vision API can quickly classify images into thousands of categories and assign them sensible labels. It can even detect individual objects, faces, and pieces of text within an image.\n",
    "\n",
    "On a very high level, Google's Vision API lets you do two things:\n",
    "- Use the API directly from your code for doing powerful image analysis that too as scale. \n",
    "- Build custom models using the API to accommodate more flexibility for your particular use case.\n",
    "\n",
    "This API is particularly very useful because as the modern day progresses the need for \"Full-Stack\" practitioners is increasing very rapidly. Now, consider a scenario where a Full-Stack web developer (this essentially means that the developer is equipped with both the front-end and back-end technologies related to web development) is asked build a website that takes images and detects its kind. Now, this would certainly require a good amount of knowledge in Computer Vision (if he does not already) because the developer will have to instruct his back-end code in such a way that it can accurately detect a given image. Also, assume that the deadline is not very long.\n",
    "\n",
    "Now, in a situation like this, if the developers starts to learn Computer Vision from scratch and then implements the required tasks he is more likely to miss the deadline. Instead if he uses some pre-trained computer vision models and learn the underlying concepts as he proceeds towards the development, it would be more practical. This is exactly one of those situations where the Vision API comes in handy. The API provides many state-of-the-art pre-trained models to serve many real-world business use-cases. \n",
    "\n",
    "The term \"Full-Stack\" is also getting associated with roles like _Machine Learning Engineer_, _Data Scientist_ etc. A Full-Stack Machine Learning Practitioner/Data Scientist is supposed design and develop or at least know the end-to-end business processes. This includes \"Making Production-ready Models\" as one of the most crucial steps wherein the concerned person/team wraps the developed model into an API or a set of APIs and deploys on the production environment. Now, the term _production_ varies accordingly to the use-cases but the general idea/framework of the processes remains the same.  The Vision API lets you easily train custom vision models with _[AutoML Vision BETA](https://cloud.google.com/automl/)_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! By now, you should have got a pretty good overview of Vision API. A nice little experiment that you can do on the [Vision homepage](https://cloud.google.com/vision/) is to analyze your favorite images and derive useful insights with the help of Vision. Here are the steps to do this:\n",
    "- Go to [Vision homepage](https://cloud.google.com/vision/).\n",
    "- It has a section called \"Try the API\". It lets you to drag/upload an image in its interface.\n",
    "    <img src = \"https://image.ibb.co/dbx5fA/Capture.jpg\"></img>\n",
    "- Once you suuply an image to it it provides you with a bunch of information regarding the image:\n",
    "    <img src = \"https://image.ibb.co/bZm3YV/Capture.jpg\"></img>\n",
    "  As you can see, Vision detected many facts about the supplied image within no time. Feel free to explore the other tabs as well to learn even more about the image. \n",
    "  \n",
    "Consider this task if it was to be performed on a set of billion images. Using an API like this would certainly be fruitful in that regard. Now, let's learn about the offerings of Vision API as to see some examples real-world use-cases the API has served to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the offerings of Vision API - Some niche use-cases: \n",
    "\n",
    "The Vision API is known for its accurate results. Vision API [documentation](https://cloud.google.com/vision/docs/tutorials) provides an excellent collection of tutorials which gives you a very detailed insight about the API. But for a first glance, these things may appear to be overwhelming. So, to keep things simple, you will learn about few use cases which have been already served by Vision API. \n",
    "\n",
    "- **Optical Character Recognition (OCR)**: This is a classic example of Computer Vision which primarily deals with extraction of text from an image. The Vision API comprises many state-of-th-art approaches for doing this.  \n",
    "- **Detection of Image Properties**: This is the task that you performed in the earlier section. With Vision API you can retrive  general attributes of an image, its features such as dominant color.\n",
    "- **Label Detection**: This task annotates an image with a label (or \"tag\") based on the image content. For example, a picture of a dog may produce a label of \"dog\", \"animal\", or some other similar annotation. This is an extremely important step in the field of [Content-based Information Retrieval](http://www.intelligence.tuc.gr/~petrakis/courses/multimedia/retrieval.pdf).\n",
    "- **Face Detection**: Given an image or set of images the task is to detect the faces present in them. This has several large applications like Surveillance Systems. \n",
    "\n",
    "These are some of the excellent use-cases on which Vision API performs seamlessly and you can integrate any of the above into your applications within very less amount of time. If you want to learn more use-cases  like these, be sure to check out [these tutorials](https://cloud.google.com/vision/docs/tutorials). \n",
    "\n",
    "Vision API provides support for a wide range of languages like `Go`, `C#`, `Java`, `PHP`, `Node.js`, `Python`, `Ruby`. In the next sections, you will see how to use Vision API in Python. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vision API Client Library for Python:\n",
    "The first step for using the Python variant of Vision API, you will have to install it. The best way to install it is through `pip`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One the installation is successful, the next step is to verify if it is really successful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above line of code executes successfully, you are ready to proceed. Google provides a series of amazing tutorials on [using Vision API in Python](https://developers.google.com/api-client-library/python/apis/vision/v1). \n",
    "\n",
    "Now, you will build a simple application in Python which will be able to detect some general attributes of an image, such as *dominant color*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A case study with Vision API in Python:\n",
    "\n",
    "Your application will take a path of an image as its input and it will display the general attributes of the corresponding image. This is useful when the images are located inside the computer on which the application is going to be executed. But what if you need to read an image from the internet? The Vision API supports reading images from the internet as well. \n",
    "\n",
    "In this case study, you will learn to tackle the first scenario. But it's only a matter of one line of code to accommodate the internet variant.  \n",
    "\n",
    "As always, you will start off by importing `vision` from `google.cloud` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to call `ImageAnnotatorClient()` which contains the utilities for extracting image properties.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will most likely run into an error if `GOOGLE_APPLICATION_CREDENTIALS` environment variable is not set. This is because these libraries use _Application Default Credentials (ADC)_ to locate your application's credentials. When your code uses libraries like this, the strategy checks for your credentials. \n",
    "\n",
    "Follow [this link](https://console.cloud.google.com/apis/credentials) to learn how to generate `GOOGLE_APPLICATION_CREDENTIALS`. Your aim is to generate a `client_secrets.json` file which you will use for authentication purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once `client_secrets.json` is obtained, you will execute the following code to set the `GOOGLE_APPLICATION_CREDENTIALS` environment variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"client_secrets.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now running the below code should not give you any error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = vision.ImageAnnotatorClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now write code for reading an image through a given path. Let's take the following image for this purpose. Feel free to use an image of your choice. \n",
    "\n",
    "<center><img src = \"https://i.ibb.co/Cw3CRFt/file-20180212-58348-7huv6f.jpg\"></img></center>\n",
    "\n",
    "**[Image Courtesy](https://theconversation.com/pet-theft-is-on-the-rise-with-more-than-60-dogs-stolen-in-the-uk-every-week-91418)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "\n",
    "path = 'Image.jpeg'\n",
    "with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have successfully loaded an image into your workspace. Now, you will instantiate an object of type `vision.types.Image` and you will supply `content=content` as its argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = vision.types.Image(content=content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are only left with the final steps of your Image Properties detection application. In these steps, you will:\n",
    "- Call `client.image_properties` with as `(image=image)` argument.\n",
    "- Store the response of `image_properties()` in a variable `response` and extract the image properties by calling the `image_properties_annotation` argument of `response`. \n",
    "- Display several properties of the images in a formatted manner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.image_properties(image=image)\n",
    "props = response.image_properties_annotation\n",
    "print('Properties of the image:')\n",
    "\n",
    "for color in props.dominant_colors.colors:\n",
    "    print('Fraction: {}'.format(color.pixel_fraction))\n",
    "    print('\\tr: {}'.format(color.color.red))\n",
    "    print('\\tg: {}'.format(color.color.green))\n",
    "    print('\\tb: {}'.format(color.color.blue))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might again run into again run into errors if you have not enable Vision API for your application. Enabling the API is extremely easy and the error trace provides the instructions so that you can enable it quickly. \n",
    "\n",
    "After enabling the API you will have to enable `Billing` as well to use the Vision API. Utilities for Image Properties detection take only $0.60. After that is done the code is executed successfully and produces the output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src = \"https://image.ibb.co/h5RJiV/Capture.jpg\"></img></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congrats!\n",
    "\n",
    "You saw how easy it is to use the Vision API and the kind of utilities that it provides that too at an extremely less cost. Today, many companies and organizations are getting benefited from this API be it for business purposes or research grounds. In this tutorial, you merely scratched the surface of Vision API but this should serve you as good starting point to use Machine Learning APIs for your applications. \n",
    "\n",
    "Make sure you check out the whole suite of Machine Learning APIs that Google provides and it is known as [CloudML](https://cloud.google.com/ml-engine/).\n",
    "\n",
    "You can build several cool applications with the help of these easily callable APIs. The links to Vision API and CloudML provide an amazing compilation of tutorials so that you can easily play with them. Good luck! \n",
    "\n",
    "If you are interesting in knowing more about Image Processing take DataCamp's [Convolutional Neural Networks for Image Processing](https://www.datacamp.com/courses/convolutional-neural-networks-for-image-processing?tap_a=5644-dce66f&tap_s=3575%2040-5b28dd) course. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
