{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Spreadsheets in PostgreSQL\n",
    "\n",
    "In this tutorial, learn how to import a spreadsheet into PostgreSQL and perform analysis on it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spreadsheets are probably one of the most pertinent elements in an organization (be it of any kind). Often times, there are situations where you need to have a very important spreadsheet(s) imported in a database server so that it can effectively be queried. In this tutorial, you will learn how to do this in PostgreSQL. \n",
    "\n",
    "This tutorial assumes that you are already familiar with SQL and how to write simple SQL queries in PostgreSQL If you are new to SQL, following are some resources which might help you - \n",
    "* [Intro to SQL for Data Science](https://www.datacamp.com/courses/intro-to-sql-for-data-science)\n",
    "* [Beginner's introduction to PostgreSQL](https://goo.gl/DV1rhY)\n",
    "\n",
    "This tutorial is divided into following two major sections - \n",
    "- Converting a spreadsheet into a .csv file\n",
    "- Importing a .csv file into a PostgreSQL database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting a spreadsheet into a .csv file\n",
    "\n",
    "To get started you will need a spreadsheet to proceed with. You can use simply create a spreadsheet in any Excel editor like Google Sheets, MS-Excel etc. To be able to follow along with this tutorial, you can use [this spreadsheet](https://drive.google.com/file/d/1JTBbTL1XFfpxuXQlNmMHgWGonMQz8pKD/view?usp=sharing) containing the following columns - \n",
    "- ID\n",
    "- Name\n",
    "- Age\n",
    "- Percentage Marks\n",
    "\n",
    "The spreadsheet has a total of 20 records. \n",
    "\n",
    "Let's quickly look at snapshot (containing the first 10 rows) of the spreadsheet - \n",
    "![](https://i.ibb.co/0XBb2jQ/Capture-1.png)\n",
    "\n",
    "The spreadsheet contains information of a few college students."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can infer the probable datatypes of the columns from the snapshot - \n",
    "* ID, Age and Percentage Marks are numeric columns. More specifically, ID and Age columns can be of integer type and the column `Percentage Marks` can be of float type. \n",
    "* The column `Name` is of character datatype. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to import this spreadsheet (you can refer to it as dataset as well) into a PostgreSQL database is to first convert the spreadsheet into a .csv file and then import it in a PostgreSQL database. CSV stands for comma-separated values. This is two main advantages - \n",
    "* .csv files are much lighter than spreadsheets and therefore easier to handle in low memory. \n",
    "* There are many in-built utilities in PostgreSQL to handle .csv files in efficient ways. \n",
    "\n",
    "Every Excel editor lets you convert a spreadsheet into a .csv file. On Google Sheets, you can do it using this navigation - File -> Download as -> Comma-separated values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing a .csv file into a PostgreSQL database\n",
    "\n",
    "Now to be able to import the .csv file you just created into a PostgreSQL database, you will need a PostgreSQL database first. Let's quickly create one using the `pgAdmin` interface. \n",
    "\n",
    "You can create a database with any name with your choice. When you are done with that, you will need to create a table in that database which will hold the entries of the .csv file which you are going to import.  Let's create a table named `Student_Records` in the database you just created. \n",
    "\n",
    "```SQL\n",
    "CREATE TABLE Student_Records\n",
    "(\n",
    "  ID serial NOT NULL,\n",
    "  Name varchar(50),\n",
    "  Age SMALLINT,\n",
    "  Percentage_Marks float8\n",
    ");\n",
    "```\n",
    "\n",
    "You kept the datatypes of the columns as discussed above. For convenience, you kept the column names the same as well. Now navigate to the table you just created in `pgAdmin` and right click on the table and select `Import` from the options. For your reference - https://bit.ly/2RZlI6m.\n",
    "\n",
    "You can ignore the errors that happened during the imports as seen in the screencast. You can verify if the records were imported properly or not by running a `select` query. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now how the above can be done using the `psql` prompt. For doing that let's first truncate the table `Student_Records` using `truncate table Student_Records;` query. \n",
    "\n",
    "Now, open up a `psql` prompt which should look like - \n",
    "![](https://i.ibb.co/S7YH1Rk/Capture-4.png)\n",
    "\n",
    "Now switch to the database that you created for importing the spreadsheet initially. You can switch to a database in PostgreSQL using the following command - \n",
    "```sql\n",
    "\\c database_name\n",
    "```\n",
    "\n",
    "If it was successful the `psql` prompt will get changed to the name of the database you specified. You can now issue the following command to have the .csv file imported into `Students_Records` table - \n",
    "\n",
    "```sql\n",
    "COPY Student_Records(ID,Name,Age,Percentage_Marks) FROM 'D:\\Students.csv' DELIMITER ',' CSV HEADER;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now execute a `select` query to verify if the import was done right. \n",
    "\n",
    "You find more about the `Copy` command from [here](http://www.postgresqltutorial.com/import-csv-file-into-posgresql-table/) and play with its different options. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "That is all for this tutorial. You can now import spreadsheet into PostgreSQL and do your analysis just as you do with normal SQL tables. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
